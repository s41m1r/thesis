\section{Combining Questionnaire and Trace Data}
\label{sec:combining-questionnaier-and-trace}

\todo[inline]{Damjan work. This work is to better understand resources. Do we need to put a subjective perspective in this thesis?}

This section proposes a new approach that combines two different perspectives on the same phenomenon. First, a questionnaire is used to gather user-subjective information from domain experts on specific items. Second, trace data are used which provide the ground truth to objectively analyze those items. Finally, inductive reasoning is used to draw conclusions and suggest recommendations.



\subsection{Approach for evaluating SMEs}

The proposed approach builds on the established SDM evaluation approaches. However, unlike existing approaches that base their SDM evaluation on stakeholder perceptions, the proposed approach complements stakeholder perceptions with data from development tools’ logs. The approach comprises four phases as shown in Figure $\ldots$ .  

\todo[inline]{Add Figure: The proposed SDM evaluation approach}

\paragraph{Phase 1 – Identification of SDM elements }

In phase 1 SDM elements for evaluation are first identified and catalogued with the help of key stakeholders knowledgeable about their SDM (e.g. process managers, project managers, senior developers). After the SDM elements are catalogued the management has to identify the stakeholders importantly affected by specific SDM elements. This means that developers who perform certain SDM activity should be the ones to evaluate this SDM activity from a developer perspective. Likewise, managers responsible for certain SDM activity should be the ones to evaluate this SDM activity from managerial perspective. Similar logic is applied also to other stakeholders importantly affected by specific SDM elements. 

\paragraph{Phase 2 – Survey and analysis }

Phase 2 starts with the creation of questionnaires based on the predefined template questions that are used to create specific questions for each SDM element catalogued in phase 1. Different questioners are created for each stakeholder based on the predefined template questions. In line with the established measures from studies presented in the literature review the developers report their perceptions about their use and satisfaction concerning a certain SDM element. Similarly, management reports their perceptions about SDM impact on iron triangle measures of overall project success (cost, speed and quality) and process engineers report their perceptions about SDM element level of assimilation, relative advantage and compatibility. The questions are written in form of statements where answers are given on 7-point Likert scale. The template statements are presented in Figure 1. 

To analyze stakeholder perceptions, we position SDM elements in a multidimensional space based on the average measurement of each stakeholder perception (dimension). It is typically difficult to further improve SDM elements that are considered highly beneficial by all stakeholders since they are all already satisfied with them. On the contrary, SDM elements that are considered unbeneficial by all stakeholders have high potential for improvement, since it is likely that most stakeholders will support their change. The SDM elements where perceptions of stakeholders greatly differ require further examination where log analysis (phase 3) has an important role to identify appropriate improvement actions. 

\paragraph{Phase 3 – Analysis of SD logs for selected elements }

In phase 3 log analysis is performed focusing on selected SDM elements. Log analysis helps to ascertain the objectiveness of different stakeholders’ perceptions and gain additional information about certain SDM elements like time spent on execution of this element by developers and quality of its execution.  

First, relevant event logs are identified. Relevant event logs are those logs which store information about the actual SDM elements. A first manual inspection of the information contained in such logs is then performed in order to identify whether essential information are present. In this paper, we are interested in information about resources and activities.  

Second, logs are often unstructured or not ready to be analyzed. Therefore, a preprocessing step is required in order to transform these logs into a format which can be further analyzed by process mining techniques. For instance, data can be transformed into a tabular format such a CSV. A useful event log must contain information about at least three aspects: case (i.e., which instance of the process is stored), activity (what activity is done in the instance), and timestamp (when is an activity performed).  

Third, it is possible that the resulting table contains a high number of attributes. It is a challenge to find the adequate attributes that properly describe what activity was done by whom and at what time. Thus, it is important at this stage to define mappings between activities in the log and the exact aspects that are being studied. This mapping can then lead to selecting certain attributes over others. For instance, in the case of bug-fixing there are many attributes that can be selected as timestamp. However, it is important to select attributes about when the bug was assigned to an engineer and when this bug was fixed, ignoring intermediate updates.  

Forth, a process analysis is performed on the log. This paper, focuses on analyzing event logs through process discovery algorithms. More specifically, it applies process mining on the event logs, taking into account the mapping of the event log to the activities. In order to perform this step, the event log may be sliced and filtered into several sub-logs, depending on the aspect of reality which is intended to be analyzed. As a result, several insights in the form of process models and statics are made available for further analysis by the user. 

\paragraph{Phase 4 – Recommendations}

This phase is concerned with the development of recommendations for improvements. Specifically, the results from the previous phase are analyzed and put into context. Particular attention is paid to outliers. For instance, significant deviations from Agile guidelines, might be a bad practice to follow. Recommendations would pinpoint such cases.  

\subsection{Case Study}

This section describes the case study. 

\subsubsection{Case study research methodology}

The proposed approach was tested in an Austrian SME software development company located in Vienna. The company can be considered a typical central European SME. The company develops software products for the field of Customer Communication Management paying special attention to the areas of document composition, workflow and document distribution. Their customers come from eight different central and southern European countries. 

A single case study design was employed to assess the proposed approach. Such design is appropriate when it captures the circumstances and conditions of an everyday or commonplace situation (Yin, 2008). The studied company represents a typical SME in the software development industry. To collect the data, we conducted interviews with management and process engineer, directly observed their workday, surveyed all the employees involved in company’s software development process and collected software development tool logs. 

All participants of our study were experienced developers having worked as members of the same team for at least two years. 

\subsubsection{Identification of SDM elements (phase 1)}

\subsubsection{Survey and analysis of stakeholder perceptions of the identified SDM elements (phase 1)}


For the purpose of analysis, we visualize perceptions of two different stakeholders on a scatter chart. 



\todo[inline]{Put chart here}

1st level of analysis (perception level of analysis): 



Helps us detect which activities to investigate further with log analysis. Interesting activities include: bug fixing, implementing new code, assigning from backlog to sprint, daily meetings, defining feature specifications. 

\subsubsection{Dataset generation}

The company uses the JIRA issue tracking software to keep change of the various tasks being performed by the employees. Employees in this case are software engineers and developers. We collected all activities done by employees during the time period between the dates 2015-12-30 and 2017-05-16.  The JIRA log was further preprocessed to generate various tabular datasets and event logs that can be used by process mining tools. For what concerns the tabular datasets, we created specific attributes to keep count of the different activities performed. Focus activities were bug fixing, implementing new code and feature specification. As typical tasks in software engineering projects are part of sprints, we aggregated the information into two-week intervals. This helps us to shed light into tasks that were delayed or dragged along slowly. Furthermore, we kept included in our dataset the users who performed the various activities.  

For what concerns process mining event logs, we did not apply any aggregation as different process mining techniques work with different levels of granularity. Thus, we focused on generating event logs for respectively bug fixing, implementing new code and feature specification. As a results we obtained XES files which are the input of our analyses from a process perspective. 

Chosen elements were performed by six different resources. Such resources are reported anonymously as p1, p2, p3, p4, p5, p6. Some tasks were completed in the system without being assigned to any resource. To capture this, we included a special resource named “no resource”.  

\subsubsection{Analysis of SD logs for the selected elements (phase 3)}

Part of analysis interpretation: 

For feature specification it seems to be the case that specifications are being updated constantly throughout the project. Additionally, most feature specifications are “Unassigned” and interestingly "Unassigned" seems to be the best performer with (64% of cases completed in sprints 1-14). So the dissatisfaction between developers and process engineer might be the consequence of firstly, the inability of company to stabilize the requirements (which then affects the high bug fixing numbers where the changes to specifications are (most likely) implemented) and secondly, too informal specification gathering process (we can speculate that they do not have change control board) which results in frequent specification changes. 

Furthermore, based on the results in 1,2 and 3, we can speculate that assigning from backlog to sprint is seen as relatively good from developer and process engineer perspectives as it works for new code (94 of 112 activities are completed in sprint 1), however from management broader perspective most of the specifications are actually “reopened” later and resolved through bug fixing which is the cause of quality and speed issues.  


To demonstrate our approach, we take Bug fixing as it is one of the most extreme in perception differences between management, developers and process engineers. 

